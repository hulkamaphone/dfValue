{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f53bf9",
   "metadata": {},
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "1738fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install yfinance package.\n",
    "!pip install yfinance html5lib --q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cec5a7",
   "metadata": {},
   "source": [
    "#### Define list of stocks\n",
    "TODO: create screener to feed this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "d39478cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stock tickers you want to analyze\n",
    "stock_list = [\"AAPL\", \"BRK-B\", \"NVDA\", \"MSFT\", \"GOOGL\", \"AMZN\", \"V\", \"PLTR\", \"OKLO\", \"BABA\", \"BIDU\", \"QCOM\", \"JD\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266f96c",
   "metadata": {},
   "source": [
    "#### Define function to import metrics from a given stock list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "1028b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def get_stock_financial_metrics(ticker_symbol):\n",
    "    \"\"\"\n",
    "    Retrieves key financial metrics for a given stock ticker using yfinance.\n",
    "\n",
    "    Args:\n",
    "        ticker_symbol (str): The stock ticker symbol (e.g., \"AAPL\", \"MSFT\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the financial metrics.\n",
    "              Returns None for metrics not available.\n",
    "              Returns an error message string if the ticker is invalid or data cannot be fetched.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker_symbol)\n",
    "        info = stock.info\n",
    "\n",
    "        # A more robust check for valid ticker data\n",
    "        if not info or 'symbol' not in info or info.get('symbol', '').lower() != ticker_symbol.lower():\n",
    "            # Check if it's a known \"bad\" ticker pattern from yfinance for delisted/problematic ones\n",
    "            if info.get('regularMarketPrice') is None and info.get('logo_url') == '': # Common pattern for invalid tickers\n",
    "                 return f\"Could not retrieve valid data for ticker: {ticker_symbol}. It might be an invalid or delisted ticker.\"\n",
    "            # If 'symbol' is present but doesn't match, it's odd, but let's flag it.\n",
    "            # If 'symbol' is missing, it's definitely problematic.\n",
    "            if 'symbol' not in info:\n",
    "                return f\"Could not retrieve valid data for ticker: {ticker_symbol}. Essential 'symbol' info missing.\"\n",
    "\n",
    "\n",
    "        metrics = {\n",
    "            \"ticker\": ticker_symbol, # Ensure ticker is always present\n",
    "            \"price\": info.get('currentPrice', info.get('regularMarketPrice', info.get('previousClose'))),\n",
    "            \"pe_ratio\": info.get('trailingPE', info.get('forwardPE')),\n",
    "            \"eps\": info.get('trailingEps', info.get('forwardEps')),\n",
    "            \"roe\": info.get('returnOnEquity'),\n",
    "            \"roa\": info.get('returnOnAssets'),\n",
    "            \"profit_margin\": info.get('profitMargins'), # Added profit margin\n",
    "            \"book_value_per_share\": info.get('bookValue'),\n",
    "            \"shares_outstanding\": info.get('sharesOutstanding'),\n",
    "            \"price_to_book\": info.get('priceToBook'),\n",
    "            \"shortName\": info.get('shortName') # Adding company name for clarity\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        # For truly problematic tickers, yfinance might raise an exception before .info\n",
    "        # or if .info itself is problematic (e.g., not a dict)\n",
    "        return {\n",
    "            \"ticker\": ticker_symbol,\n",
    "            \"price\": None,\n",
    "            \"pe_ratio\": None,\n",
    "            \"eps\": None,\n",
    "            \"roe\": None,\n",
    "            \"roa\": None,\n",
    "            \"profit_margin\": None, # Added profit margin\n",
    "            \"book_value_per_share\": None,\n",
    "            \"shares_outstanding\": None,\n",
    "            \"price_to_book\": None,\n",
    "            \"shortName\": f\"Error: {str(e)}\", # Store error in a field\n",
    "            \"error_message\": str(e) # Explicit error message field\n",
    "        }\n",
    "\n",
    "\n",
    "def get_financials_for_stock_list(ticker_list):\n",
    "    \"\"\"\n",
    "    Fetches financial metrics for a list of stock tickers and returns them as a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        ticker_list (list): A list of stock ticker symbols (e.g., [\"AAPL\", \"MSFT\", \"GOOGL\"]).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the financial metrics for each stock.\n",
    "                          Includes an 'error_message' column for tickers where data couldn't be fetched.\n",
    "    \"\"\"\n",
    "    all_metrics_data = []\n",
    "    for ticker in ticker_list:\n",
    "        #print(f\"Fetching data for {ticker}...\")\n",
    "        data = get_stock_financial_metrics(ticker)\n",
    "        \n",
    "        # If the function returns a string (our old error handling), convert to dict\n",
    "        if isinstance(data, str) and \"Could not retrieve\" in data: # Check for our specific error string\n",
    "            metrics_dict = {\n",
    "                \"ticker\": ticker, \"price\": None, \"pe_ratio\": None, \"eps\": None,\n",
    "                \"roe\": None, \"roa\": None, \"profit_margin\": None, # Added profit margin\n",
    "                \"book_value_per_share\": None, \"shares_outstanding\": None, \n",
    "                \"price_to_book\": None, \"shortName\": None,\n",
    "                \"error_message\": data\n",
    "            }\n",
    "        elif isinstance(data, dict):\n",
    "            metrics_dict = data\n",
    "            if \"error_message\" not in metrics_dict: # Ensure error_message field exists\n",
    "                 metrics_dict[\"error_message\"] = None\n",
    "        else: # Should not happen with current get_stock_financial_metrics\n",
    "            metrics_dict = {\n",
    "                \"ticker\": ticker, \"price\": None, \"pe_ratio\": None, \"eps\": None,\n",
    "                \"roe\": None, \"roa\": None, \"profit_margin\": None, # Added profit margin\n",
    "                \"book_value_per_share\": None, \"shares_outstanding\": None, \n",
    "                \"price_to_book\": None, \"shortName\": None,\n",
    "                \"error_message\": \"Unknown error structure from get_stock_financial_metrics\"\n",
    "            }\n",
    "            \n",
    "        all_metrics_data.append(metrics_dict)\n",
    "        \n",
    "    # Create DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(all_metrics_data)\n",
    "    \n",
    "    # Reorder columns to have ticker and shortName first, and error_message last\n",
    "    if not df.empty:\n",
    "        cols = [\"ticker\", \"shortName\", \"price\", \"pe_ratio\", \"eps\", \"roe\", \"roa\", \"profit_margin\",\n",
    "                \"book_value_per_share\", \"shares_outstanding\", \"price_to_book\", \"error_message\"]\n",
    "        # Filter out columns not present in the DataFrame (e.g., if all tickers failed identically)\n",
    "        existing_cols = [col for col in cols if col in df.columns]\n",
    "        df = df[existing_cols]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b522426",
   "metadata": {},
   "source": [
    "#### Execute function with current stock list and store into df \"successful_data_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "5762ab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting financial data retrieval...\n"
     ]
    }
   ],
   "source": [
    "# Execute conditional for each stock and return specified metrics.\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting financial data retrieval...\")\n",
    "    financials_df = get_financials_for_stock_list(stock_list)\n",
    "\n",
    "    #print(\"\\n--- Financial Data DataFrame ---\")\n",
    "    #print(financials_df)\n",
    "\n",
    "    # Further analysis or saving the DataFrame\n",
    "    if not financials_df.empty:\n",
    "        #print(\"\\n--- DataFrame Info ---\")\n",
    "        #financials_df.info()\n",
    "\n",
    "        # Example: Filter out rows with errors for cleaner analysis\n",
    "        successful_data_df = financials_df[financials_df['error_message'].isnull()].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "        \n",
    "        # Convert relevant columns to numeric, coercing errors to NaN\n",
    "        numeric_cols = [\"price\", \"pe_ratio\", \"eps\", \"roe\", \"roa\", \"profit_margin\", \n",
    "                        \"book_value_per_share\", \"shares_outstanding\", \"price_to_book\"]\n",
    "        for col in numeric_cols:\n",
    "            if col in successful_data_df.columns:\n",
    "                successful_data_df[col] = pd.to_numeric(successful_data_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5485691",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b996e89f",
   "metadata": {},
   "source": [
    "#### Add alternative ticker for ValueInvesting.io website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "71879c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define alternative ticker mapping for ValueInvesting.io\n",
    "stock_replacement_map = {\n",
    "    'BRK-B': 'BRK.A',\n",
    "    'JD': '9618.HK'\n",
    "}\n",
    "\n",
    "# Add alt ticker column based on mapping.\n",
    "successful_data_df['alt_ticker'] = successful_data_df['ticker'].map(stock_replacement_map)\n",
    "\n",
    "# Create new stock list to feed valueinvesting.io scraper function.\n",
    "stock_list_vi = [stock_replacement_map.get(x,x) for x in stock_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "58c16a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd # Import pandas for DataFrame\n",
    "import numpy as np # For np.nan, though pd.NA is often preferred\n",
    "from tabulate import tabulate # Import tabulate for pretty printing DataFrames\n",
    "\n",
    "def extract_div_value_by_class(url, div_class_name, instance_number=1):\n",
    "    \"\"\"\n",
    "    Extracts the text value from the Nth instance of a div element\n",
    "    with the specified class name on a given URL. (Kept for general use)\n",
    "    \"\"\"\n",
    "    if not isinstance(instance_number, int) or instance_number < 1:\n",
    "        #print(f\"Error: instance_number must be a positive integer. Received: {instance_number}\")\n",
    "        return None\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        all_target_divs = soup.find_all('div', class_=div_class_name)\n",
    "        if len(all_target_divs) >= instance_number:\n",
    "            target_div = all_target_divs[instance_number - 1]\n",
    "            value = target_div.get_text(strip=True)\n",
    "            return value\n",
    "        else:\n",
    "            # print(f\"Could not find instance {instance_number} of div with class '{div_class_name}'. \"\n",
    "            #       f\"Found {len(all_target_divs)} instance(s) on the page: {url}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        #print(f\"Error during requests to {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        #print(f\"An unexpected error occurred while processing {url} with extract_div_value_by_class: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_value_from_nested_div(url, parent_tag_name, parent_class_name, \n",
    "                                  child_tag_name, child_class_name, \n",
    "                                  parent_instance_number=1, child_instance_number=1):\n",
    "    \"\"\"\n",
    "    Finds the Nth instance of a parent element by its tag and class,\n",
    "    and then finds the Nth instance of a child element (by its tag and class)\n",
    "    within that parent. Extracts the text from the child.\n",
    "    (Kept for two-level nesting if needed)\n",
    "    \"\"\"\n",
    "    if not isinstance(parent_instance_number, int) or parent_instance_number < 1:\n",
    "        #print(f\"Error: parent_instance_number must be a positive integer. Received: {parent_instance_number}\")\n",
    "        return None\n",
    "    if not isinstance(child_instance_number, int) or child_instance_number < 1:\n",
    "        #print(f\"Error: child_instance_number must be a positive integer. Received: {child_instance_number}\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        all_parent_elements = soup.find_all(parent_tag_name, class_=parent_class_name)\n",
    "\n",
    "        if len(all_parent_elements) >= parent_instance_number:\n",
    "            parent_element = all_parent_elements[parent_instance_number - 1] \n",
    "            \n",
    "            all_child_elements = parent_element.find_all(child_tag_name, class_=child_class_name)\n",
    "            \n",
    "            if len(all_child_elements) >= child_instance_number:\n",
    "                child_element = all_child_elements[child_instance_number - 1] \n",
    "                return child_element.get_text(strip=True)\n",
    "            else:\n",
    "                #print(f\"Child instance {child_instance_number} of '{child_tag_name}.{child_class_name}' not found within parent instance {parent_instance_number} of '{parent_tag_name}.{parent_class_name}' on {url}. \"\n",
    "                #      f\"Found {len(all_child_elements)} child instances.\")\n",
    "                return None\n",
    "        else:\n",
    "            #print(f\"Parent instance {parent_instance_number} of '{parent_tag_name}.{parent_class_name}' not found on the page: {url}. \"\n",
    "            #      f\"Found {len(all_parent_elements)} parent instances.\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        #print(f\"Error during requests to {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        #print(f\"An unexpected error occurred while processing {url} with extract_value_from_nested_div: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_value_from_deeply_nested_div(url, \n",
    "                                         gp_tag, gp_class, gp_instance,\n",
    "                                         p_tag, p_class, p_instance,\n",
    "                                         c_tag, c_class, c_instance):\n",
    "    \"\"\"\n",
    "    Extracts text from a deeply nested element:\n",
    "    Nth child (c) within Nth parent (p) within Nth grandparent (gp).\n",
    "    \"\"\"\n",
    "    if not all(isinstance(i, int) and i >= 1 for i in [gp_instance, p_instance, c_instance]):\n",
    "        #print(\"Error: All instance numbers (grandparent, parent, child) must be positive integers.\")\n",
    "        return None\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # 1. Find Grandparent\n",
    "        all_grandparent_elements = soup.find_all(gp_tag, class_=gp_class)\n",
    "        if len(all_grandparent_elements) < gp_instance:\n",
    "            #print(f\"Grandparent instance {gp_instance} of '{gp_tag}.{gp_class}' not found on {url}. Found {len(all_grandparent_elements)}.\")\n",
    "            return None\n",
    "        grandparent_element = all_grandparent_elements[gp_instance - 1]\n",
    "\n",
    "        # 2. Find Parent within Grandparent\n",
    "        all_parent_elements = grandparent_element.find_all(p_tag, class_=p_class)\n",
    "        if len(all_parent_elements) < p_instance:\n",
    "            #print(f\"Parent instance {p_instance} of '{p_tag}.{p_class}' not found within grandparent instance {gp_instance} on {url}. Found {len(all_parent_elements)}.\")\n",
    "            return None\n",
    "        parent_element = all_parent_elements[p_instance - 1]\n",
    "\n",
    "        # 3. Find Child within Parent\n",
    "        all_child_elements = parent_element.find_all(c_tag, class_=c_class)\n",
    "        if len(all_child_elements) < c_instance:\n",
    "            #print(f\"Child instance {c_instance} of '{c_tag}.{c_class}' not found within parent instance {p_instance} (of grandparent instance {gp_instance}) on {url}. Found {len(all_child_elements)}.\")\n",
    "            return None\n",
    "        child_element = all_child_elements[c_instance - 1]\n",
    "        \n",
    "        return child_element.get_text(strip=True)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        #print(f\"Error during requests to {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        #print(f\"An unexpected error occurred while processing {url} with extract_value_from_deeply_nested_div: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def clean_and_convert_value_to_numeric(value_input):\n",
    "    \"\"\"\n",
    "    Cleans a string value by stripping text, handling suffixes (B, M, K),\n",
    "    and currency symbols, then converts to a numeric type (float).\n",
    "    Returns pd.NA if conversion is not possible or input is unsuitable.\n",
    "    \"\"\"\n",
    "    if isinstance(value_input, (int, float)): # Already numeric\n",
    "        return float(value_input)\n",
    "    if not isinstance(value_input, str) or not value_input.strip():\n",
    "        # Handles None, empty strings, or non-string types that aren't numeric\n",
    "        return pd.NA\n",
    "\n",
    "    value_str = value_input.strip()\n",
    "    multiplier = 1.0\n",
    "    numeric_part_str = value_str\n",
    "\n",
    "    original_length = len(numeric_part_str)\n",
    "    if numeric_part_str.upper().endswith('B'):\n",
    "        multiplier = 1_000_000_000.0\n",
    "        numeric_part_str = numeric_part_str[:-1].strip()\n",
    "    elif numeric_part_str.upper().endswith('M'):\n",
    "        multiplier = 1_000_000.0\n",
    "        numeric_part_str = numeric_part_str[:-1].strip()\n",
    "    elif numeric_part_str.upper().endswith('K'):\n",
    "        multiplier = 1_000.0\n",
    "        numeric_part_str = numeric_part_str[:-1].strip()\n",
    "    \n",
    "    if original_length > 0 and len(numeric_part_str) == 0 and original_length == 1 and value_str.upper() in ['B', 'M', 'K']:\n",
    "         return pd.NA\n",
    "\n",
    "    chars_to_remove_after_suffix = \"$€£,\" \n",
    "    for char_to_remove in chars_to_remove_after_suffix:\n",
    "        numeric_part_str = numeric_part_str.replace(char_to_remove, '')\n",
    "    \n",
    "    numeric_part_str = numeric_part_str.strip()\n",
    "\n",
    "    if not numeric_part_str: \n",
    "        return pd.NA\n",
    "\n",
    "    try:\n",
    "        numeric_value = float(numeric_part_str)\n",
    "        return numeric_value * multiplier\n",
    "    except ValueError:\n",
    "        return pd.NA \n",
    "    except Exception:\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Dynamic URL Generation ---\n",
    "    base_url_template = \"https://valueinvesting.io/{TICKER}/valuation/dcf-growth-exit-5y\"\n",
    "    urls_to_scrape = [base_url_template.format(TICKER=value) for value in stock_list_vi]\n",
    "    \n",
    "    # --- Configuration for DEEPLY nested extraction ---\n",
    "    # Grandparent: first instance of div class 'fs col-lg-2'\n",
    "    gp_tag_config = 'div'\n",
    "    gp_class_config = 'fs col-lg-2' # Class names with spaces are handled directly\n",
    "    gp_instance_config = 1\n",
    "\n",
    "    # Parent: second instance of div class 'price_square' (within grandparent)\n",
    "    p_tag_config = 'div'\n",
    "    p_class_config = 'price_square' # Using 'price_square' as requested\n",
    "    p_instance_config = 2\n",
    "\n",
    "    # Child: second instance of div class 'norm' (within parent)\n",
    "    c_tag_config = 'div'\n",
    "    c_class_config = 'norm'\n",
    "    c_instance_config = 1\n",
    "    \n",
    "    results_data = [] \n",
    "\n",
    "    #print(f\"Starting extraction for {len(urls_to_scrape)} URLs.\")\n",
    "    #print(f\"Targeting: Child Inst#{c_instance_config} ('{c_tag_config}.{c_class_config}') \"\n",
    "    #      f\"within Parent Inst#{p_instance_config} ('{p_tag_config}.{p_class_config}') \"\n",
    "    #      f\"within Grandparent Inst#{gp_instance_config} ('{gp_tag_config}.{gp_class_config}')\\n\")\n",
    "\n",
    "    for current_url in urls_to_scrape:\n",
    "        #print(f\"Processing URL: {current_url}\")\n",
    "        ticker = None\n",
    "        try:\n",
    "            url_parts = current_url.split('/')\n",
    "            if len(url_parts) > 3 and url_parts[2].endswith(\"valueinvesting.io\"): \n",
    "                ticker = url_parts[3]\n",
    "            elif \"nonexistentwebsite.com\" in current_url:\n",
    "                 ticker = \"N/A_NonExistentSite\"\n",
    "            elif \"google.com\" in current_url: \n",
    "                ticker = \"N/A_Google\"\n",
    "            else: \n",
    "                ticker = \"N/A_UnknownFormat\"\n",
    "        except Exception as e_ticker:\n",
    "            #print(f\"  Could not extract ticker from URL {current_url}: {e_ticker}\")\n",
    "            ticker = \"N/A_ExtractionError\"\n",
    "\n",
    "        # Using the new deeply nested extraction function\n",
    "        raw_extracted_value = extract_value_from_deeply_nested_div(\n",
    "            current_url,\n",
    "            gp_tag_config, gp_class_config, gp_instance_config,\n",
    "            p_tag_config, p_class_config, p_instance_config,\n",
    "            c_tag_config, c_class_config, c_instance_config\n",
    "        )\n",
    "        \n",
    "        processed_value_for_df = raw_extracted_value \n",
    "\n",
    "        results_data.append({\n",
    "            \"url\": current_url,\n",
    "            \"ticker\": ticker, \n",
    "            \"target_grandparent\": f\"Inst#{gp_instance_config} {gp_tag_config}.{gp_class_config}\",\n",
    "            \"target_parent\": f\"Inst#{p_instance_config} {p_tag_config}.{p_class_config}\",\n",
    "            \"target_child\": f\"Inst#{c_instance_config} {c_tag_config}.{c_class_config}\",\n",
    "            \"extracted_raw_value\": raw_extracted_value,\n",
    "            \"processed_value\": processed_value_for_df \n",
    "        })\n",
    "        #print(\"-\" * 40) \n",
    "\n",
    "    # write to dataframe.\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "\n",
    "    # Split currency out from processed_value and convert value to numeric in USD terms.\n",
    "    # Use regex to extract number and currency separately\n",
    "    results_df[['value', 'currency']] = results_df['processed_value'].str.extract(r'([\\d,\\.]+)\\s*([A-Z]{3})')\n",
    "\n",
    "    # Clean the numeric values: remove commas and convert to float\n",
    "    results_df['value'] = results_df['value'].str.replace(',', '', regex=False).astype(float)\n",
    "\n",
    "    # Function to fetch FX rate to USD\n",
    "    def get_fx_rate(currency_code):\n",
    "        if pd.isna(currency_code):\n",
    "            return np.nan\n",
    "        ticker = f\"{currency_code}USD=X\"\n",
    "        try:\n",
    "            data = yf.Ticker(ticker).history(period=\"1d\")\n",
    "            return data['Close'].iloc[-1] if not data.empty else np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching rate for {ticker}: {e}\")\n",
    "            return np.nan\n",
    "\n",
    "    # Get FX rates\n",
    "    results_df['fx_rate'] = results_df['currency'].apply(get_fx_rate)\n",
    "\n",
    "    # Convert amounts to USD\n",
    "    results_df['amount_usd'] = results_df['value'] * results_df['fx_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf9fac",
   "metadata": {},
   "source": [
    "#### Combine DCF values into analysis table and calulate opportunity.\n",
    "Opportuniy = % difference between 5 Year Growth DCF Fair Value and current share price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "07b7369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Primary merge on 'ticker'\n",
    "merged_df = successful_data_df.merge(\n",
    "    results_df[['ticker', 'processed_value', 'amount_usd']],\n",
    "    on='ticker',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 2: Identify where fallback is needed\n",
    "missing_mask = merged_df['processed_value'].isna() & successful_data_df['alt_ticker'].notna()\n",
    "\n",
    "# Step 3: Get fallback values from alt_ticker\n",
    "# Map alt_ticker to both processed_value and amount_usd\n",
    "fallback_dict = results_df.set_index('ticker')[['processed_value', 'amount_usd']].to_dict(orient='index')\n",
    "\n",
    "fallback_rows = successful_data_df.loc[missing_mask, 'alt_ticker'].map(fallback_dict)\n",
    "fallback_df = pd.DataFrame(fallback_rows.tolist(), index=fallback_rows.index)\n",
    "\n",
    "# Step 4: Fill missing values in merged_df\n",
    "for col in ['processed_value', 'amount_usd']:\n",
    "    merged_df.loc[missing_mask, col] = fallback_df[col]\n",
    "\n",
    "# Step 5: Rename processed_value to dcf_5yg, leave amount_usd as-is\n",
    "merged_df = merged_df.rename(columns={'processed_value': 'dcf_5yg'})\n",
    "\n",
    "# Calculate opportunity (percentage diff between DCF fair value and share price).\n",
    "merged_df['opportunity'] = np.where(\n",
    "    merged_df['amount_usd'] != 0,\n",
    "    ((merged_df['price'] - merged_df['amount_usd']) / merged_df['amount_usd']) * 100,\n",
    "    np.nan  # or some default value or message\n",
    ")\n",
    "\n",
    "# Cleanup column names.\n",
    "merged_df = merged_df.rename(columns={\n",
    "    'price_to_book': 'pb',\n",
    "    'amount_usd': 'dcf_5y_usd',\n",
    "    'pe_ratio': 'pe'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf61a3",
   "metadata": {},
   "source": [
    "#### Analysis: Explore DF, get top opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "0a310188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "      <th>pe</th>\n",
       "      <th>roe</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>dcf_5y_usd</th>\n",
       "      <th>opportunity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BIDU</td>\n",
       "      <td>84.39</td>\n",
       "      <td>8.372024</td>\n",
       "      <td>0.09374</td>\n",
       "      <td>0.19415</td>\n",
       "      <td>138.47000</td>\n",
       "      <td>-39.055391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BABA</td>\n",
       "      <td>117.18</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>0.11438</td>\n",
       "      <td>0.13059</td>\n",
       "      <td>152.43000</td>\n",
       "      <td>-23.125369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>148.34</td>\n",
       "      <td>15.121304</td>\n",
       "      <td>0.42205</td>\n",
       "      <td>0.26110</td>\n",
       "      <td>180.09000</td>\n",
       "      <td>-17.630074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>205.70</td>\n",
       "      <td>33.556280</td>\n",
       "      <td>0.25240</td>\n",
       "      <td>0.10140</td>\n",
       "      <td>240.85000</td>\n",
       "      <td>-14.594146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>171.86</td>\n",
       "      <td>19.202234</td>\n",
       "      <td>0.34789</td>\n",
       "      <td>0.30857</td>\n",
       "      <td>196.58000</td>\n",
       "      <td>-12.575033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRK-B</td>\n",
       "      <td>506.18</td>\n",
       "      <td>13.494535</td>\n",
       "      <td>0.13187</td>\n",
       "      <td>0.21788</td>\n",
       "      <td>554.50000</td>\n",
       "      <td>-8.714157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V</td>\n",
       "      <td>362.40</td>\n",
       "      <td>36.349045</td>\n",
       "      <td>0.50655</td>\n",
       "      <td>0.52859</td>\n",
       "      <td>324.15000</td>\n",
       "      <td>11.800093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>199.95</td>\n",
       "      <td>31.144860</td>\n",
       "      <td>1.38015</td>\n",
       "      <td>0.24301</td>\n",
       "      <td>176.25000</td>\n",
       "      <td>13.446809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>139.19</td>\n",
       "      <td>44.900000</td>\n",
       "      <td>1.15463</td>\n",
       "      <td>0.51694</td>\n",
       "      <td>109.86000</td>\n",
       "      <td>26.697615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>JD</td>\n",
       "      <td>32.94</td>\n",
       "      <td>8.053789</td>\n",
       "      <td>0.16283</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>24.12266</td>\n",
       "      <td>36.552103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>458.68</td>\n",
       "      <td>35.474090</td>\n",
       "      <td>0.33610</td>\n",
       "      <td>0.35789</td>\n",
       "      <td>282.92000</td>\n",
       "      <td>62.123568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLTR</td>\n",
       "      <td>122.32</td>\n",
       "      <td>531.826050</td>\n",
       "      <td>0.12357</td>\n",
       "      <td>0.18321</td>\n",
       "      <td>5.09000</td>\n",
       "      <td>2303.143418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OKLO</td>\n",
       "      <td>52.93</td>\n",
       "      <td>-135.717960</td>\n",
       "      <td>-0.56027</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker   price          pe      roe  profit_margin  dcf_5y_usd  opportunity\n",
       "10   BIDU   84.39    8.372024  0.09374        0.19415   138.47000   -39.055391\n",
       "9    BABA  117.18   15.750000  0.11438        0.13059   152.43000   -23.125369\n",
       "11   QCOM  148.34   15.121304  0.42205        0.26110   180.09000   -17.630074\n",
       "5    AMZN  205.70   33.556280  0.25240        0.10140   240.85000   -14.594146\n",
       "4   GOOGL  171.86   19.202234  0.34789        0.30857   196.58000   -12.575033\n",
       "1   BRK-B  506.18   13.494535  0.13187        0.21788   554.50000    -8.714157\n",
       "6       V  362.40   36.349045  0.50655        0.52859   324.15000    11.800093\n",
       "0    AAPL  199.95   31.144860  1.38015        0.24301   176.25000    13.446809\n",
       "2    NVDA  139.19   44.900000  1.15463        0.51694   109.86000    26.697615\n",
       "12     JD   32.94    8.053789  0.16283        0.03760    24.12266    36.552103\n",
       "3    MSFT  458.68   35.474090  0.33610        0.35789   282.92000    62.123568\n",
       "7    PLTR  122.32  531.826050  0.12357        0.18321     5.09000  2303.143418\n",
       "8    OKLO   52.93 -135.717960 -0.56027        0.00000         NaN          NaN"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return key metrics, order by opportunity \"margin of satefy to 5Y fair value\".\n",
    "merged_df[['ticker', 'price', 'pe', 'roe', 'profit_margin', 'dcf_5y_usd', 'opportunity']].sort_values(by='opportunity', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1a072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
